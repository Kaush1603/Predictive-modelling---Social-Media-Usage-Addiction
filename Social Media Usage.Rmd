---
title: "Class Project"
author: "Tarun Kaushik"
date: "2023-04-21"
output: html_document
---

```{r}

library(car)
library(readr)
library(MVA)
library(HSAUR2)
library(SciViews)
library(scatterplot3d)
library(car)
library(lattice)
library(GGally)
library(ggplot2)
library(ggridges)
library(ggvis)
library(ggcorrplot)
library(ggthemes)
library(cowplot)
library(gapminder)
library(gganimate)
library(dplyr)
library(grid)
library(gridExtra)
library(RColorBrewer)
library(Hotelling)
library(stats)
library(biotools)
library(factoextra)
library(FactoMineR)
library(ggfortify)
library(psych)
library(corrplot)
library(cluster)
library(factoextra)
library(magrittr)
library(NbClust)
library(caret)
library(zoo)
library(caTools)
library(randomForest)
library(nnet)
library(robustHD)



data <- read.csv("C:/Users/tarun/OneDrive/Desktop/Multivariate Dataset - Wine/class project/Class_Survey.csv", header = TRUE)

#removed the variable number of times app opened
data <- data[,-15]
str(data)

#remove NA
numeric_cols <- sapply(data, is.numeric)
data[, numeric_cols] <- na.aggregate(data[, numeric_cols], FUN = mean)
any(is.na(data))

#spliting the data for train and test
target_data <- data[3:15]
target_data <- target_data[,-12]

# creating a stratified random sample of row indices for the testing set
set.seed(123)

split = sample.split(target_data$Social.Media.Addiction, SplitRatio = 0.70)
train_data = subset(target_data, split == TRUE)
test_data = subset(target_data, split == FALSE)

#train data splitted for predictive variable and target variable
Xtrain_data <- train_data[,1:11]
Ytrain_data <- train_data[,12]
head(Xtrain_data)

dummy_Ytrain_data <- predict(dummyVars("~ .", data.frame(target = Ytrain_data)), newdata = data.frame(target = Ytrain_data))

#test data splitted for predictive variable and target variable
Xtest_data <- test_data[,1:11]
Ytest_data <- test_data[,12]
dummy_Ytest_data <- predict(dummyVars("~ .", data.frame(target = Ytest_data)), newdata = data.frame(target = Ytest_data))


#summary of the data
summary(target_data[-12])




#Feature selection and dimentionality reduction using Randomforest
#Convert the one-hot encoded target variable to a factor variable.
Ytrain_data_factored <- apply(dummy_Ytrain_data, 1, which.max)










#Train the random forest model using the training data (Xtrain_data and Ytrain_data).
rf_model <- randomForest(x = Xtrain_data, y = Ytrain_data_factored)
varImpPlot(rf_model)

imp <- importance(rf_model)
imp

imp_values <- imp[, "IncNodePurity"]
imp_values


important_features <- colnames(Xtrain_data)[imp_values > 2]
important_features

Xtrain_data_selected <- Xtrain_data[, important_features]
head(Xtrain_data_selected)


##Building logistic regression

##Scale the data
Xtrain_data_scaled <- scale(Xtrain_data_selected)
Xtrain_data_scaled_df <- as.data.frame(Xtrain_data_scaled)
#removing outliers from the data
Xtrain_data_winsorized <- as.data.frame(winsorize(as.matrix(Xtrain_data_scaled), probs = c(0.01, 0.99)))

#convert factor into 0 and 1 from 1 and 2 as per model requirement
Ytrain_data_binary <- ifelse(Ytrain_data_factored == 1, 1, 0)

#fit the model
model <- glm(Ytrain_data_binary ~ ., data = Xtrain_data_winsorized, family = binomial)
summary(model)


##trying to improve the model

Xtrain_data_scaled_new <- Xtrain_data_scaled[,-c(1,3,5)]
Xtrain_data_winsorized_new <- as.data.frame(winsorize(as.matrix(Xtrain_data_scaled_new), probs = c(0.01, 0.99)))

model_new <- glm(Ytrain_data_binary ~ ., data = Xtrain_data_winsorized_new, family = binomial)

summary(model_new)

#Lets predict and evaluate the model
Xtest_data_scaled_new <- scale(Xtest_data)
Xtest_data_scaled_new <- Xtest_data_scaled_new[,-c(1,3,5)]
head(Xtest_data_scaled_new)

Xtest_data_scaled_new <- Xtest_data_scaled_new[, c(1,7)]
head(Xtest_data_scaled_new)



Xtest_data_winsorized_new <- as.data.frame(winsorize(as.matrix(Xtest_data_scaled_new), probs = c(0.01, 0.99)))




Ytest_pred <- predict(model_new, newdata = Xtest_data_winsorized_new, type = "response")
Ytest_pred_binary <- ifelse(Ytest_pred > 0.5, 0, 1)

Ytest_data_factored <- apply(dummy_Ytest_data, 1, which.max)
Ytest_data_binary <- ifelse(Ytest_data_factored == 1, 0, 1)

Ytest_data_binary <- factor(Ytest_data_binary, levels = c(0, 1))
Ytest_pred_binary <- factor(Ytest_pred_binary, levels = c(0, 1))
confusionMatrix(Ytest_data_binary, Ytest_pred_binary)


##The confusion matrix provides a summary of the performance of the model on the test data.

##The model correctly predicted 38 out of 53 instances of churn (positive class) and 12 out of 23 instances of non-churn (negative class).
##The accuracy of the model is 0.717, which means that the model correctly predicted 71.7% of the instances.

##Overall, the model seems to perform moderately well in predicting the churn/non-churn outcomes. However, there is still room for improvement in the performance, especially in terms of PPV and specificity.

```
